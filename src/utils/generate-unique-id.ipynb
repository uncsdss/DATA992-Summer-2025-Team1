{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbe43e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Processed 193 files → ../uuid_file_map.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import uuid\n",
    "import csv\n",
    "import json\n",
    "import yaml  \n",
    "from typing import Any, Callable\n",
    "\n",
    "def generate_uuid(path: str) -> uuid.UUID:\n",
    "    with open(path, 'rb') as f:\n",
    "        content = f.read()\n",
    "    digest = hashlib.sha256(content).hexdigest()\n",
    "    return uuid.uuid5(uuid.NAMESPACE_URL, digest)\n",
    "\n",
    "def prepend_to_file(path: str, text: str):\n",
    "    with open(path, 'r+', encoding='utf-8') as f:\n",
    "        original = f.read()\n",
    "        f.seek(0)\n",
    "        f.write(text + original)\n",
    "\n",
    "def insert_structured(\n",
    "    path: str,\n",
    "    file_uuid: uuid.UUID,\n",
    "    loader: Callable[..., Any],\n",
    "    dumper: Callable[..., Any],\n",
    "    is_yaml: bool = False\n",
    "):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        data = loader(f) or {}\n",
    "    if not isinstance(data, dict):\n",
    "        return\n",
    "    if 'uuid' in data:\n",
    "        return\n",
    "    \n",
    "    new_data = {'uuid': str(file_uuid), **data}\n",
    "\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        if is_yaml:\n",
    "            dumper(new_data, f, sort_keys=False)\n",
    "        else:\n",
    "            dumper(new_data, f, indent=2)\n",
    "\n",
    "    print(f\"Generated key for {path}\")\n",
    "\n",
    "def insert_comment(path: str, file_uuid: uuid.UUID, marker: str):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        head = f.read().splitlines()[:5]\n",
    "    if any(line.startswith(marker) for line in head):\n",
    "        return\n",
    "    prepend_to_file(path, f\"{marker} {file_uuid}\\n\")\n",
    "    print(f\"Generated key for {path}\")\n",
    "\n",
    "def process_files(repo_path: str, csv_output_path: str):\n",
    "\n",
    "    handlers = {\n",
    "        '.json': lambda p, u: insert_structured(p, u, json.load,   json.dump,    False),\n",
    "        '.yml':  lambda p, u: insert_structured(p, u, yaml.safe_load,yaml.safe_dump, True),\n",
    "        '.yaml': lambda p, u: insert_structured(p, u, yaml.safe_load,yaml.safe_dump, True),\n",
    "        '.adoc': lambda p, u: insert_comment   (p, u, '// uuid:'),\n",
    "    }\n",
    "\n",
    "    mapping = []\n",
    "    for root, _, files in os.walk(repo_path):\n",
    "        for fname in files:\n",
    "            ext = os.path.splitext(fname)[1].lower()\n",
    "            if ext not in handlers:\n",
    "                continue\n",
    "            full = os.path.join(root, fname)\n",
    "            u = generate_uuid(full)\n",
    "            handlers[ext](full, u)\n",
    "            rel = os.path.relpath(full, repo_path)\n",
    "            mapping.append((str(u), rel))\n",
    "\n",
    "    with open(csv_output_path, 'w', newline='', encoding='utf-8') as out:\n",
    "        writer = csv.writer(out)\n",
    "        writer.writerow(['uuid', 'relative_path'])\n",
    "        writer.writerows(mapping)\n",
    "\n",
    "    print(f\"\\n✅ Processed {len(mapping)} files → {csv_output_path}\")\n",
    "\n",
    "process_files(\n",
    "    repo_path='../bluexp-dataset',\n",
    "    csv_output_path='../uuid_file_map.csv'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
